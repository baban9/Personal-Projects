{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Import Libraries\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, LSTM, Embedding,Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints,optimizers, layers\n",
    "from keras.layers import Dense, Input, Flatten, Dropout,BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file\n",
    "file_content = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check sample content in the email\n",
    "file_content['v2'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "stop = stopwords.words('english')\n",
    "file_content['v2'] = file_content['v2'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unwanted columns\n",
    "Email_Data = file_content[['v1', 'v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go jurong point, crazy.. Available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say early hor... U c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                              Email\n",
       "0    ham  Go jurong point, crazy.. Available bugis n gre...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3    ham          U dun say early hor... U c already say...\n",
       "4    ham          Nah I think goes usf, lives around though"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column names\n",
    "Email_Data = Email_Data.rename(columns={\"v1\":\"Target\", \"v2\":\"Email\"})\n",
    "Email_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "stop = stopwords.words('english')\n",
    "file_content['v2'] = file_content['v2'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unwanted columns\n",
    "Email_Data = file_content[['v1', 'v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go jurong point, crazy.. Available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say early hor... U c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                              Email\n",
       "0    ham  Go jurong point, crazy.. Available bugis n gre...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3    ham          U dun say early hor... U c already say...\n",
       "4    ham          Nah I think goes usf, lives around though"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column names\n",
    "Email_Data = Email_Data.rename(columns={\"v1\":\"Target\", \"v2\":\"Email\"})\n",
    "Email_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazy available bugis n great ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3                  u dun say early hor u c already say\n",
       "4             nah i think goes usf lives around though\n",
       "Name: Email, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete punctuations, convert text in lower case and delete the double space\n",
    "Email_Data['Email'] = Email_Data['Email'].apply(lambda x:re.sub('[!@#$:).;,?&]','', x.lower()))\n",
    "Email_Data['Email'] = Email_Data['Email'].apply(lambda x:re.sub(' ', ' ', x))\n",
    "Email_Data['Email'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating text(input) and target classes\n",
    "list_sentences_rawdata = Email_Data[\"Email\"].fillna(\"_na_\").values\n",
    "list_classes = [\"Target\"]\n",
    "target = Email_Data[list_classes].values\n",
    "To_Process=Email_Data[['Email', 'Target']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test split with 80:20 ratio\n",
    "train, test = train_test_split(To_Process, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8350 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Define the sequence lengths, max number of words and embedding dimensions\n",
    "# Sequence length of each sentence. If more, truncate. If less, pad with zeros\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "\n",
    "# Top 20000 frequently occurring words\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "# Get the frequently occurring words\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train.Email)\n",
    "train_sequences = tokenizer.texts_to_sequences(train.Email)\n",
    "test_sequences = tokenizer.texts_to_sequences(test.Email)\n",
    "\n",
    "\n",
    "# dictionary containing words and their index\n",
    "word_index = tokenizer.word_index\n",
    "# print(tokenizer.word_index)\n",
    "# total words in the corpus\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the top frequent words on train\n",
    "train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the top frequent words on test\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 300)\n",
      "(1115, 300)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train['Target']\n",
    "test_labels = test['Target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# converts the character array to numeric array. Assigns levels to unique labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (4457, 300)\n",
      "Shape of label tensor: (4457, 2)\n",
      "Shape of label tensor: (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "# changing data types\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "labels_train = to_categorical(np.asarray(train_labels))\n",
    "labels_test = to_categorical(np.asarray(test_labels))\n",
    "print('Shape of data tensor:', train_data.shape)\n",
    "print('Shape of label tensor:', labels_train.shape)\n",
    "print('Shape of label tensor:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "print(MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\baban\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning the model \n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS,EMBEDDING_DIM,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\baban\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/5\n",
      "4457/4457 [==============================] - 22s 5ms/step - loss: 0.4009 - acc: 0.8378 - val_loss: 0.4620 - val_acc: 0.8457\n",
      "Epoch 2/5\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.1595 - acc: 0.9435 - val_loss: 0.6216 - val_acc: 0.8457\n",
      "Epoch 3/5\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0778 - acc: 0.9782 - val_loss: 0.3608 - val_acc: 0.8457\n",
      "Epoch 4/5\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0488 - acc: 0.9886 - val_loss: 0.4370 - val_acc: 0.8619\n",
      "Epoch 5/5\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0389 - acc: 0.9910 - val_loss: 0.5438 - val_acc: 0.9534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1222a4abe08>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, labels_train, batch_size=64, epochs=5, validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5295881 , 0.47041187],\n",
       "       [0.576681  , 0.42331898],\n",
       "       [0.58025044, 0.41974956],\n",
       "       ...,\n",
       "       [0.24285339, 0.75714666],\n",
       "       [0.5782141 , 0.4217859 ],\n",
       "       [0.57895905, 0.42104095]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions on test data\n",
    "predicted=model.predict(test_data)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.94864048 0.99180328]\n",
      "recall: [0.99893955 0.70348837]\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(labels_test, predicted.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscore: [0.9731405  0.82312925]\n",
      "support: [943 172]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       943\n",
      "           1       0.99      0.70      0.82       172\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1115\n",
      "   macro avg       0.97      0.85      0.90      1115\n",
      "weighted avg       0.96      0.95      0.95      1115\n",
      " samples avg       0.95      0.95      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(sklearn.metrics.classification_report(labels_test, predicted.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SIMPLERNN model.\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "#model training\n",
    "print('Training SIMPLERNN model.')\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH ))\n",
    "model.add(SimpleRNN(2, input_shape=(None,1)))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\baban\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/5\n",
      "4457/4457 [==============================] - 29s 6ms/step - loss: 0.4072 - accuracy: 0.9437 - val_loss: 0.2764 - val_accuracy: 0.9722\n",
      "Epoch 2/5\n",
      "4457/4457 [==============================] - 28s 6ms/step - loss: 0.1791 - accuracy: 0.9897 - val_loss: 0.1975 - val_accuracy: 0.9713\n",
      "Epoch 3/5\n",
      "4457/4457 [==============================] - 27s 6ms/step - loss: 0.0835 - accuracy: 0.9953 - val_loss: 0.1472 - val_accuracy: 0.9623\n",
      "Epoch 4/5\n",
      "4457/4457 [==============================] - 28s 6ms/step - loss: 0.0383 - accuracy: 0.9980 - val_loss: 0.1427 - val_accuracy: 0.9489\n",
      "Epoch 5/5\n",
      "4457/4457 [==============================] - 28s 6ms/step - loss: 0.0223 - accuracy: 0.9987 - val_loss: 0.1429 - val_accuracy: 0.9489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1222c0cef08>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, labels_train,batch_size=16,epochs=5,validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03912038, 0.9608796 ],\n",
       "       [0.97968644, 0.02031357],\n",
       "       [0.9459999 , 0.05400007],\n",
       "       ...,\n",
       "       [0.11900423, 0.88099575],\n",
       "       [0.8923687 , 0.1076313 ],\n",
       "       [0.76538324, 0.2346168 ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction on test data\n",
    "predicted_Srnn=model.predict(test_data)\n",
    "predicted_Srnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(labels_test, predicted_Srnn.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.94657258 0.96747967]\n",
      "recall: [0.99575822 0.69186047]\n",
      "fscore: [0.97054264 0.80677966]\n",
      "support: [943 172]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       943\n",
      "           1       0.97      0.69      0.81       172\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1115\n",
      "   macro avg       0.96      0.84      0.89      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      " samples avg       0.95      0.95      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(sklearn.metrics.classification_report(labels_test,predicted_Srnn.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baban\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"relu\", return_sequences=True, units=16, recurrent_activation=\"hard_sigmoid\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "print('Training LSTM model.')\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS,EMBEDDING_DIM,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(LSTM(output_dim=16, activation='relu', inner_activation='hard_sigmoid',return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/5\n",
      "4457/4457 [==============================] - 62s 14ms/step - loss: 0.1272 - accuracy: 0.9565 - val_loss: 0.2181 - val_accuracy: 0.9623\n",
      "Epoch 2/5\n",
      "4457/4457 [==============================] - 64s 14ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.0734 - val_accuracy: 0.9767\n",
      "Epoch 3/5\n",
      "4457/4457 [==============================] - 63s 14ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0889 - val_accuracy: 0.9785\n",
      "Epoch 4/5\n",
      "4457/4457 [==============================] - 59s 13ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0807 - val_accuracy: 0.9821\n",
      "Epoch 5/5\n",
      "4457/4457 [==============================] - 61s 14ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1095 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1222da27648>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(train_data, labels_train,batch_size=16,epochs=5,validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.5197310e-05, 9.9993479e-01],\n",
       "       [9.6274668e-01, 3.7253309e-02],\n",
       "       [9.9966562e-01, 3.3437929e-04],\n",
       "       ...,\n",
       "       [2.1405364e-12, 1.0000000e+00],\n",
       "       [9.9982184e-01, 1.7818072e-04],\n",
       "       [9.9991643e-01, 8.3569561e-05]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction on text data\n",
    "predicted_lstm=model.predict(test_data)\n",
    "predicted_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.97614108 0.98675497]\n",
      "recall: [0.99787911 0.86627907]\n",
      "fscore: [0.9868904  0.92260062]\n",
      "support: [943 172]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       943\n",
      "           1       0.99      0.87      0.92       172\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.98      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      " samples avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(labels_test,\n",
    "predicted_lstm.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "\n",
    "print(sklearn.metrics.classification_report(labels_test,predicted_lstm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bidirectional LSTM model.\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "print('Training Bidirectional LSTM model.') \n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS,EMBEDDING_DIM,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True,dropout=0.1, recurrent_dropout=0.1)))\n",
    "model.add(Conv1D(16, kernel_size = 3, padding = \"valid\",kernel_initializer = \"glorot_uniform\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/3\n",
      "4457/4457 [==============================] - 73s 16ms/step - loss: 0.1543 - accuracy: 0.9457 - val_loss: 0.0805 - val_accuracy: 0.9830\n",
      "Epoch 2/3\n",
      "4457/4457 [==============================] - 63s 14ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0732 - val_accuracy: 0.9839\n",
      "Epoch 3/3\n",
      "4457/4457 [==============================] - 65s 15ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0695 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12238f482c8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(train_data, labels_train,batch_size=16,epochs=3,validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.5050768e-04, 9.9944943e-01],\n",
       "       [9.2666931e-02, 9.0733308e-01],\n",
       "       [9.9864823e-01, 1.3517353e-03],\n",
       "       ...,\n",
       "       [2.4379567e-06, 9.9999762e-01],\n",
       "       [9.9972814e-01, 2.7180091e-04],\n",
       "       [9.9940467e-01, 5.9538323e-04]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction on test data\n",
    "predicted_blstm=model.predict(test_data)\n",
    "predicted_blstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.98430962 0.98742138]\n",
      "recall: [0.99787911 0.9127907 ]\n",
      "fscore: [0.99104792 0.94864048]\n",
      "support: [943 172]\n",
      "############################\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(labels_test,predicted_blstm.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       943\n",
      "           1       0.99      0.91      0.95       172\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.99      0.96      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      " samples avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(labels_test,predicted_blstm.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
