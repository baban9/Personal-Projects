{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text summarization of article/document using different algorithms in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text summarization is the process of making large documents into smaller ones without losing the context, which eventually saves readers time. This can be done using different techniques like the following:\n",
    "    • TextRank: A graph-based ranking algorithm\n",
    "    • Feature-based text summarization\n",
    "    • LexRank: TF-IDF with a graph-based algorithm\n",
    "    • Topic based\n",
    "    • Using sentence embeddings\n",
    "    • Encoder-Decoder Model: Deep learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "TextRank is the graph-based ranking algorithm for NLP. It is basically inspired by PageRank, which is used in the Google search engine but particularly designed for text. It will extract the topics, create nodes out of\n",
    "them, and capture the relation between nodes to summarize the text.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup and urllib libraries to fetch data from Wikipedia.\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get data from Wikipedia\n",
    "def get_only_text(url):\n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page)\n",
    "    text = ' '.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    #print (text)\n",
    "    return soup.title.text, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the Wikipedia url\n",
    "url=\"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "# Call the function created above\n",
    "text = get_only_text(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of letters \n",
    "len(''.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d414d226f318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Lets see first 1000 letters from the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# Lets see first 1000 letters from the text\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " enter your resume : Triplebyte screens and evaluates thousands of engineers per month to find the best candidates for our partner companies. Human decision making doesn't work at our scale; our marketplace is powered by automated assessment and decision making. Triplebyte has three cornerstone ML products: our quiz, our interview, and our matchmaking. As a machine learning engineer, you'll be responsible for the end-to-end process of designing and running experiments to serving production models at scale. Some of our pipelines use off the shelf components, but we're also implementing custom models and techniques from the latest research papers. We're also building forecasting tools for internal teams to measure and predict outcomes. This is an ideal role for an engineer or data scientist who wants the scope and responsibility to own features/products from the inception and research phase through to measuring real-world results. Fields your work will touch on  Psychometrics Recommender systems Time series analysis Survival analysis Bayesian inference Probabilistic programming Requirements  Robust exploratory/experimental skills. We have a novel dataset of candidate profiles and interview outcomes from our candidate screening process and our hiring marketplace. You'll be responsible for designing and evaluating experiments to predict downstream outcomes. Ability to implement models from research. Some of our best improvements in both speed and predictiveness has come from doing literature surveys and implementing novel techniques from research papers. Engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating against our back-end services. About Triplebyte  Triplebyte is a hiring marketplace used by companies like Apple, Dropbox, Stripe, and Instacart to hire the best technical talent. We are on a mission to build a meritocratic hiring process, and we do all our evaluation background blind. Our ultimate goal is to collect the largest dataset and use this to build the world's best technical hiring process. No other company has successfully done what we're doing in this field.  We are growing extremely quickly, working on a problem that is fundamental, sitting at the crossroads between the workforce and employers. Ten years from now, it'll look silly to use anything other than Triplebyte for technical hiring.  Company Culture  We have a laid-back, friendly office culture. Over lunch you'll often find us discussing the latest in technology, books, and pop culture, and then maybe getting in a quick game of chess or babyfoot (foosball).  Since we're an early-stage company, we move fast, and it's important that each member of our team is able to take ownership of projects by defining problems, brainstorming solutions, and running experiments.\n"
     ]
    }
   ],
   "source": [
    "text = input(\" enter your resume : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import summarize from gensim\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "# Convert text to string format\n",
    "text = str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Triplebyte screens and evaluates thousands of engineers per month to find the best candidates for our partner companies.\\nAs a machine learning engineer, you'll be responsible for the end-to-end process of designing and running experiments to serving production models at scale.\\nSome of our pipelines use off the shelf components, but we're also implementing custom models and techniques from the latest research papers.\\nOur ultimate goal is to collect the largest dataset and use this to build the world's best technical hiring process.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summarize the text with ratio 0.1 (10% of the total words.)\n",
    "summarize(text, ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companies\n",
      "company\n",
      "research\n",
      "engineers\n",
      "engineer\n",
      "engineering\n",
      "hiring\n",
      "hire\n",
      "outcomes\n",
      "evaluates\n",
      "evaluating\n",
      "evaluation\n",
      "production models\n",
      "products\n",
      "analysis\n",
      "novel\n",
      "forecasting\n"
     ]
    }
   ],
   "source": [
    "#keywords\n",
    "print(keywords(text, ratio=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
